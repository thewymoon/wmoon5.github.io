---
layout: post
title: "Boosted Decision Trees: Supervised Learning and Decision Trees"
date: 2016-08-12
---

Inside the particle collider at CERN, there is all sorts of madness going on. Collisions and scattering particles and energy depositions all over the place. And at the end of the day it's the job of the particle physicists upstairs (the collider is underground) to look at all the blips of data on their screen and determine what exactly just happened down there. Was that an electron? Or maybe a muon? Or some quark? Indeed, it is often relatively easy to distinguish between different types of particles and events, but alas, there are plenty of cases where it isn't so easy. 

And in addition to the different particles looking similar in the data, the reality is that particle physicists are now really only interested in the extremely rare processes and particles, so being able to accurately distinguish between an uninteresting event and an interesting one with a high degree of accuracy is of extremely great importance.

Fortunately, particle physicists have finally (better late than never) started to adopt and use machine learning tools in their research to tackle problems exactly like the one I just described. And during my time working at CERN, I had the opportunity to learn about a particular machine learning tool called a "boosted decision tree" that will be the focus of this two-part post.

But, before we talk about boosted decision trees (which from now on I'll call BDT), let's start from the basics. Using BDT's are an example of "supervised learning," which I will explain below. And once we've understood the paradigm of supervised learning, we will move on to understanding what BDT's actually are.
